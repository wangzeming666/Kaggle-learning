{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8901d682-290a-4e00-bd3c-e8e10655d8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:03:14.417854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751796194.432096    9629 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751796194.436446    9629 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751796194.447575    9629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751796194.447590    9629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751796194.447592    9629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751796194.447593    9629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 19:03:14.450883: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from scipy.stats import skew  \n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a84dfe7-5c5a-4997-9d04-614767db0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1460, 81)\n",
      "Test set size: (1459, 80)\n",
      "START data processing 2025-07-06 19:03:18.069943\n",
      "(2917, 79)\n",
      "⚠️ 跳过特征 LotArea，最大值：215245，最小值：1300，原因：The algorithm terminated without finding a valid bracket. Consider trying different initial points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangzeming/.local/lib/python3.10/site-packages/scipy/stats/_morestats.py:1340: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r, prob = _stats_py.pearsonr(xvals, yvals)\n",
      "/home/wangzeming/.local/lib/python3.10/site-packages/scipy/stats/_morestats.py:1340: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r, prob = _stats_py.pearsonr(xvals, yvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 跳过特征 1stFlrSF，最大值：5095，最小值：334，原因：The algorithm terminated without finding a valid bracket. Consider trying different initial points.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('home-data-for-ml-course/train.csv')\n",
    "test = pd.read_csv('home-data-for-ml-course/test.csv')\n",
    "print(\"Train set size:\", train.shape)\n",
    "print(\"Test set size:\", test.shape)\n",
    "print('START data processing', datetime.now(), )\n",
    "\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# Deleting outliers\n",
    "train = train[train.GrLivArea < 4500]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train.SalePrice.reset_index(drop=True)\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test\n",
    "\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "print(features.shape)\n",
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n",
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "\n",
    "features['Functional'] = features['Functional'].fillna('Typ')\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n",
    "\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n",
    "\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "\n",
    "features.update(features[objects].fillna('None'))\n",
    "\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Filling in the rest of the NA's\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "for i in skew_index:\n",
    "    try:\n",
    "        features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 跳过特征 {i}，最大值：{features[i].max()}，最小值：{features[i].min()}，原因：{e}\")\n",
    "\n",
    "\n",
    "\n",
    "features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])\n",
    "\n",
    "# simplified features\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4471b056-6a0f-41ee-b99e-52c24dfd0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 86)\n",
      "(2917, 333)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "final_features0 = pd.get_dummies(features).reset_index(drop=True)\n",
    "print(final_features0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80df15d9-409b-408f-9ad7-b8144efa58e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangzeming/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "# 原始拼接后的完整数据\n",
    "features_all = final_features0.copy()\n",
    "\n",
    "# 你已有的：降维 + 聚类\n",
    "X_pca = PCA(n_components=50).fit_transform(final_features0)\n",
    "X_umap = umap.UMAP(n_components=2).fit_transform(X_pca)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(X_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587ce85f-d04e-4b9f-8c31-b9ecf7e9c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dummies = pd.get_dummies(kmeans.labels_, prefix='umap_cluster')\n",
    "final_features = pd.concat([final_features0, cluster_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f625ea-c0d6-4e17-8017-f54db2f9927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(X):, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f575c1-187c-4c78-862b-af0a3d0135f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1458, 338) y (1458,) X_sub (1459, 338)\n"
     ]
    }
   ],
   "source": [
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270407cd-dbda-472e-93a5-1c7860c80391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1453, 336) y (1453,) X_sub (1459, 336)\n",
      "START ML 2025-07-06 19:03:30.654708\n",
      "TEST score on CV\n",
      "Kernel Ridge score: 0.1041 (0.0147)\n",
      " 2025-07-06 19:04:23.051585\n",
      "Lasso score: 0.1048 (0.0151)\n",
      " 2025-07-06 19:04:53.952496\n",
      "ElasticNet score: 0.1049 (0.0151)\n",
      " 2025-07-06 19:07:06.823295\n",
      "SVR score: 0.1049 (0.0141)\n",
      " 2025-07-06 19:07:09.703587\n",
      "Lightgbm score: 0.1055 (0.0164)\n",
      " 2025-07-06 19:07:20.644993\n",
      "GradientBoosting score: 0.1061 (0.0133)\n",
      " 2025-07-06 19:08:54.505252\n",
      "Xgboost score: 0.1071 (0.0160)\n",
      " 2025-07-06 19:09:34.648083\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "overfit.append('MSZoning_C (all)')\n",
    "\n",
    "X = X.drop(overfit, axis=1, errors='ignore')\n",
    "X_sub = X_sub.drop(overfit, axis=1, errors='ignore')\n",
    "\n",
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n",
    "\n",
    "# ################## ML ########################################\n",
    "print('START ML', datetime.now(), )\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# rmsle\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "# build our model scoring function\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y,\n",
    "                                    scoring=\"neg_mean_squared_error\",\n",
    "                                    cv=kfolds))\n",
    "    return (rmse)\n",
    "\n",
    "\n",
    "# setup models    \n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(),\n",
    "                      RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(),\n",
    "                      LassoCV(max_iter=int(1e7), alphas=alphas2,\n",
    "                              random_state=42, cv=kfolds))\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(),\n",
    "                           ElasticNetCV(max_iter=int(1e7), alphas=e_alphas,\n",
    "                                        cv=kfolds, l1_ratio=e_l1ratio))\n",
    "                                        \n",
    "svr = make_pipeline(RobustScaler(),\n",
    "                      SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =42)\n",
    "                                   \n",
    "\n",
    "lightgbm = LGBMRegressor(objective='regression', n_jobs=-1,\n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       #min_data_in_leaf=2,\n",
    "                                       #min_sum_hessian_in_leaf=11\n",
    "                                       )\n",
    "                                       \n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:squarederror', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "\n",
    "# stack\n",
    "stack_gen = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('ridge', ridge),\n",
    "        ('lasso', lasso),\n",
    "        ('elastic', elasticnet),\n",
    "        ('gbr', gbr),\n",
    "        ('xgb', xgboost),\n",
    "        ('lgb', lightgbm)\n",
    "    ],\n",
    "    final_estimator=xgboost,\n",
    "    cv=10,\n",
    "    passthrough=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "                                \n",
    "\n",
    "print('TEST score on CV')\n",
    "\n",
    "score = cv_rmse(ridge)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lasso)\n",
    "print(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"Lightgbm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"GradientBoosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a01dbdd-3723-460c-a8ca-c8abb8c55c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START Fit\n",
      "2025-07-06 19:09:34.653618 StackingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   13.6s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   23.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   31.4s remaining:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   28.5s remaining:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   33.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   44.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   53.8s remaining:   35.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  1.0min remaining:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  1.9min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:12:06.635111 elasticnet\n",
      "2025-07-06 19:12:20.632929 lasso\n",
      "2025-07-06 19:12:23.934254 ridge\n",
      "2025-07-06 19:12:29.809704 svr\n",
      "2025-07-06 19:12:30.159056 GradientBoosting\n",
      "2025-07-06 19:12:40.016506 xgboost\n",
      "2025-07-06 19:12:46.450164 lightgbm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('START Fit')\n",
    "print(datetime.now(), 'StackingRegressor')\n",
    "stack_gen_model = stack_gen.fit(X, y)\n",
    "print(datetime.now(), 'elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "print(datetime.now(), 'lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "print(datetime.now(), 'ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "print(datetime.now(), 'svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "print(datetime.now(), 'GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "print(datetime.now(), 'xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "print(datetime.now(), 'lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c901997b-0a43-4891-8e53-f7871df9162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.057587365695045294\n"
     ]
    }
   ],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.25 * stack_gen_model.predict(X)))\n",
    "            \n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2450c89-88a4-4a7e-a300-42877db277ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.059261129076075496\n"
     ]
    }
   ],
   "source": [
    "def blend_models_predict1(X):\n",
    "    return (\n",
    "        (0.1090 * elastic_model_full_data.predict(X)) +\n",
    "        (0.1091 * lasso_model_full_data.predict(X)) +\n",
    "        (0.1083 * ridge_model_full_data.predict(X)) +\n",
    "        (0.1090 * svr_model_full_data.predict(X)) +\n",
    "        (0.1038 * gbr_model_full_data.predict(X)) +\n",
    "        (0.1053 * xgb_model_full_data.predict(X)) +\n",
    "        (0.1055 * lgb_model_full_data.predict(X)) +\n",
    "        (0.25 * stack_gen_model.predict(X))\n",
    "    )\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cc84d3-737a-48b8-ba4b-bcebc0c91974",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n",
    "submission.to_csv(\"my_model_submission0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "009e7cd7-bfbb-4a7f-843e-b5a12ee9f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n",
    "submission.to_csv(\"my_model_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1febf1-9043-42e4-8778-49517d04fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融合权重： [-0.49027111  0.54690786 -0.10459108 -0.14624843  0.72452336  0.80470765\n",
      " -0.52473413  0.1913566 ]\n",
      "偏置： -0.020349336863574763\n",
      "RMSLE score on train data:\n",
      "0.02682163641777133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 构建训练数据：每列是一个模型的预测\n",
    "blend_train = np.column_stack([\n",
    "    elastic_model_full_data.predict(X),\n",
    "    lasso_model_full_data.predict(X),\n",
    "    ridge_model_full_data.predict(X),\n",
    "    svr_model_full_data.predict(X),\n",
    "    gbr_model_full_data.predict(X),\n",
    "    xgb_model_full_data.predict(X),\n",
    "    lgb_model_full_data.predict(X),\n",
    "    stack_gen_model.predict(X)\n",
    "])\n",
    "\n",
    "# 学习最优线性融合权重\n",
    "lr = LinearRegression()\n",
    "lr.fit(blend_train, y)\n",
    "\n",
    "# 查看权重\n",
    "print(\"融合权重：\", lr.coef_)\n",
    "print(\"偏置：\", lr.intercept_)\n",
    "\n",
    "# 预测函数\n",
    "def blend_models_predict2(X):\n",
    "    blend_test = np.column_stack([\n",
    "        elastic_model_full_data.predict(X),\n",
    "        lasso_model_full_data.predict(X),\n",
    "        ridge_model_full_data.predict(X),\n",
    "        svr_model_full_data.predict(X),\n",
    "        gbr_model_full_data.predict(X),\n",
    "        xgb_model_full_data.predict(X),\n",
    "        lgb_model_full_data.predict(X),\n",
    "        stack_gen_model.predict(X)\n",
    "    ])\n",
    "    return lr.predict(blend_test)\n",
    "\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict2(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a94dab7-518f-41aa-84ab-0cfbca6e5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict2(X_sub)))\n",
    "submission.to_csv(\"my_model_submission.csv2\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c074f70-21f1-4e77-8fb2-9c6b5142f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1\n",
      "step = 2\n",
      "step = 3\n",
      "step = 4\n",
      "step = 5\n",
      "step = 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "step = 0\n",
    "# 用于生成交叉验证预测（每个模型）\n",
    "elastic_oof = cross_val_predict(elastic_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "lasso_oof = cross_val_predict(lasso_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "ridge_oof = cross_val_predict(ridge_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "svr_oof = cross_val_predict(svr_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "gbr_oof = cross_val_predict(gbr_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "xgb_oof = cross_val_predict(xgb_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "lgb_oof = cross_val_predict(lgb_model_full_data, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "stack_oof = cross_val_predict(stack_gen_model, X, y, cv=10, n_jobs=-1)\n",
    "print(\"step =\", step := step + 1)\n",
    "\n",
    "# 拼接所有模型的输出\n",
    "blend_input = np.column_stack([elastic_oof, lasso_oof, ridge_oof, svr_oof,\n",
    "                               gbr_oof, xgb_oof, lgb_oof, stack_oof])\n",
    "\n",
    "# 用 Ridge 来学习融合权重\n",
    "blend_model = Ridge(alpha=1e-3)\n",
    "blend_model.fit(blend_input, y)\n",
    "\n",
    "print(\"融合权重：\", blend_model.coef_)\n",
    "print(\"偏置：\", blend_model.intercept_)\n",
    "\n",
    "blend_test_input = np.column_stack([\n",
    "    elastic_model_full_data.predict(X),\n",
    "    lasso_model_full_data.predict(X),\n",
    "    ridge_model_full_data.predict(X),\n",
    "    svr_model_full_data.predict(X),\n",
    "    gbr_model_full_data.predict(X),\n",
    "    xgb_model_full_data.predict(X),\n",
    "    lgb_model_full_data.predict(X),\n",
    "    stack_gen_model.predict(X)\n",
    "])\n",
    "\n",
    "blend_pred = blend_model.predict(blend_test_input)\n",
    "print(\"融合 RMSLE:\", rmsle(y, blend_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2e3af-cdf4-4a06-bd5c-36486891c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建测试集的预测特征\n",
    "blend_test_input_sub = np.column_stack([\n",
    "    elastic_model_full_data.predict(X_sub),\n",
    "    lasso_model_full_data.predict(X_sub),\n",
    "    ridge_model_full_data.predict(X_sub),\n",
    "    svr_model_full_data.predict(X_sub),\n",
    "    gbr_model_full_data.predict(X_sub),\n",
    "    xgb_model_full_data.predict(X_sub),\n",
    "    lgb_model_full_data.predict(X_sub),\n",
    "    stack_gen_model.predict(X_sub)\n",
    "])\n",
    "\n",
    "# 用融合模型预测测试集\n",
    "blend_models_predict3 = blend_model.predict(blend_test_input_sub)\n",
    "\n",
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:, 1] = np.floor(np.expm1(blend_models_predict3))\n",
    "submission.to_csv(\"my_model_submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c917a8e-ba4f-46dc-9ba8-55dd22ab111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a97f09-5bff-48bc-81e2-6ec63ddb2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 用当前最优融合模型预测测试集标签\n",
    "pseudo_labels = blend_models_predict1(X_sub)\n",
    "\n",
    "# 2. 构造新的训练集（包含原训练集 + 测试集伪标签）\n",
    "X_pseudo = pd.concat([X, X_sub], axis=0)\n",
    "y_pseudo = pd.concat([y, pd.Series(pseudo_labels)], axis=0)\n",
    "\n",
    "# 3. 用融合权重拟合一个 Ridge 模型来再训练（可视为 meta 模型）\n",
    "blend_input = np.column_stack([\n",
    "    elastic_model_full_data.predict(X_pseudo),\n",
    "    lasso_model_full_data.predict(X_pseudo),\n",
    "    ridge_model_full_data.predict(X_pseudo),\n",
    "    svr_model_full_data.predict(X_pseudo),\n",
    "    gbr_model_full_data.predict(X_pseudo),\n",
    "    xgb_model_full_data.predict(X_pseudo),\n",
    "    lgb_model_full_data.predict(X_pseudo),\n",
    "    stack_gen_model.predict(X_pseudo)\n",
    "])\n",
    "\n",
    "# 4. 用 Ridge 再次拟合融合权重（或保留原融合权重也可）\n",
    "blend_model_final = Ridge(alpha=1e-3)\n",
    "blend_model_final.fit(blend_input, y_pseudo)\n",
    "\n",
    "# 5. 再次对测试集预测\n",
    "blend_test_input = np.column_stack([\n",
    "    elastic_model_full_data.predict(X_sub),\n",
    "    lasso_model_full_data.predict(X_sub),\n",
    "    ridge_model_full_data.predict(X_sub),\n",
    "    svr_model_full_data.predict(X_sub),\n",
    "    gbr_model_full_data.predict(X_sub),\n",
    "    xgb_model_full_data.predict(X_sub),\n",
    "    lgb_model_full_data.predict(X_sub),\n",
    "    stack_gen_model.predict(X_sub)\n",
    "])\n",
    "\n",
    "# 6. 最终预测输出\n",
    "final_preds = blend_model_final.predict(blend_test_input)\n",
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:, 1] = np.floor(np.expm1(final_preds))\n",
    "submission.to_csv(\"my_model_submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8988d96-e480-4138-921e-723b243d3996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ad484-c886-40d0-8cb7-8d179c3314cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00565b-43e7-4928-9f55-aa50e2318a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels = blend_models_predict1(X_sub)\n",
    "X_combined = pd.concat([X, X_sub], axis=0).reset_index(drop=True)\n",
    "y_combined = pd.concat([y, pd.Series(pseudo_labels)], axis=0).reset_index(drop=True)\n",
    "step = 0\n",
    "print(\"step =\", step := step + 1)\n",
    "elastic_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "lasso_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "ridge_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "svr_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "gbr_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "xgb_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "lgb_model_full_data.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "\n",
    "stack_gen_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('ridge', ridge),\n",
    "        ('lasso', lasso),\n",
    "        ('elastic', elasticnet),\n",
    "        ('gbr', gbr),\n",
    "        ('xgb', xgboost),\n",
    "        ('lgb', lightgbm)\n",
    "    ],\n",
    "    final_estimator=xgboost,\n",
    "    cv=10,\n",
    "    passthrough=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "print(\"step =\", step := step + 1)\n",
    "stack_gen_model.fit(X_combined, y_combined)\n",
    "print(\"step =\", step := step + 1)\n",
    "train_preds = blend_models_predict(X)  \n",
    "print(\"训练集融合 RMSLE:\", rmsle(y, train_preds))\n",
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict1(X_sub)))\n",
    "submission.to_csv(\"my_model_submission4.csv\", index=False)\n",
    "submission = pd.read_csv('home-data-for-ml-course/sample_submission.csv')\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict1(X_sub)))\n",
    "submission.to_csv(\"my_model_submission5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
