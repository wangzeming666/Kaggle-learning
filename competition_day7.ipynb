{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423788d1-527d-4d41-b899-3a173375ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house_price_competition_day_2_failed_trying.ipynb', 'house_price_advanced_view.ipynb', 'addr_kmeans.pkl', 'submission.csv', 'house_price_advanced_models.ipynb', 'my_model_submission.csv1', 'my_model_submission4.csv', 'house_price', 'addr_umap.pkl', 'Day1.ipynb', 'titanic', 'house-prices-advanced-regression-techniques.zip', 'titanic.zip', 'my_model_submission3.csv', 'house_price_competition_view_day2.ipynb', 'my_model_submission0.csv', 'X_umap.npy', 'addr_tfidf.pkl', 'Day2 Housing Price.ipynb', 'pca_model.pkl', 'my_model_submission.csv', 'umap_model.pkl', 'my_model_submission1.csv', 'Untitled1.ipynb', 'house_price_view.ipynb', 'home-data-for-ml-course.zip', '.ipynb_checkpoints', 'home-data-for-ml-course', 'house_price.ipynb', 'my_model_submission2.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew \n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd2dd14-0e72-4625-96f6-d5c20b41bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded!\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('house_price/dataset.csv')\n",
    "test = pd.read_csv('house_price/test.csv')\n",
    "print (\"Data is loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1450b579-19d4-48c0-9303-365a53ecbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "quantitative.remove('sale_price')\n",
    "quantitative.remove('id')\n",
    "qualitative = [f for f in train.columns if train.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b195b228-52a4-4bc9-9e17-6ebf37342f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sale_nbr       42182\n",
      "subdivision    17550\n",
      "submarket       1717\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "missing = train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d412d23-bf95-4337-9765-6ade1b426e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sale_nbr       42412\n",
      "subdivision    17550\n",
      "submarket       1718\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "missing = test.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e5b9d9-cc19-41dd-b2b5-5071f4ab77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 46)\n",
      "(200000, 45)\n"
     ]
    }
   ],
   "source": [
    "def dataset_fill_null(obj):\n",
    "    obj['subdivision'].fillna('Unknown', inplace=True)\n",
    "    obj.drop(columns=['sale_nbr'], inplace=True)\n",
    "    obj['submarket'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "dataset_fill_null(train)\n",
    "dataset_fill_null(test)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5c5a80-f379-4f2b-9b9a-343af79e4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造原始地址字段\n",
    "train_ID = train['id']\n",
    "test_ID = test['id']\n",
    "# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "test.drop(['id'], axis=1, inplace=True)\n",
    "# Deleting outliers\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"sale_price\"] = np.log1p(train[\"sale_price\"])\n",
    "y = train.sale_price.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab6c4ae-430a-4531-8a4d-221c5e052615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_encode(df, y=None, drop_high_card=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ================= 清洗阶段 ================= #\n",
    "    addresses = (df['city'].fillna('') + ' ' + df['subdivision'].fillna('')).str.lower()\n",
    "    \n",
    "    # 分词（空格切）\n",
    "    # 用 CountVectorizer 可以保留频率稀疏性\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=1000,         # 可调大小\n",
    "        stop_words=None,      # 去常见词\n",
    "        token_pattern=r'\\b\\w+\\b',  # 标准单词\n",
    "        ngram_range=(1, 2)         # 一元和二元组都试试\n",
    "    )\n",
    "    address_vecs = vectorizer.fit_transform(addresses)\n",
    "    \n",
    "    address_df = pd.DataFrame(address_vecs.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    address_df.index = df.index\n",
    "    df = pd.concat([df, address_df], axis=1)\n",
    "    df = df.drop(columns=['city', 'subdivision'])\n",
    "\n",
    "    # 使用同一个 address_vecs（CountVectorizer 输出）\n",
    "    svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "    address_pca = svd.fit_transform(address_vecs)\n",
    "    \n",
    "    # 转成 DataFrame 并拼接\n",
    "    pca_df = pd.DataFrame(address_pca, columns=[f'address_pca_{i+1}' for i in range(address_pca.shape[1])], index=df.index)\n",
    "    df = pd.concat([df, pca_df], axis=1)\n",
    "\n",
    "    # 补充缺失类别为 'None'\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category', 'string']).columns\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('None')\n",
    "\n",
    "    # 填充数值缺失为 0\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # 拆解日期特征\n",
    "    if 'sale_date' in df.columns:\n",
    "        df['sale_year'] = pd.to_datetime(df['sale_date']).dt.year\n",
    "        df['sale_month'] = pd.to_datetime(df['sale_date']).dt.month\n",
    "        df = df.drop(columns='sale_date')\n",
    "\n",
    "    df['house_age'] = df['sale_year'] - df['year_built']\n",
    "    df['reno_age'] = df['sale_year'] - df['year_reno']\n",
    "    df['has_reno'] = (df['year_reno'] > 0).astype(int)\n",
    "    df['land_imp_ratio'] = df['land_val'] / (df['imp_val'] + 1e-5)\n",
    "\n",
    "\n",
    "    # ================= 编码阶段 ================= #\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    low_card_cols = []\n",
    "    high_card_cols = []\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            n_unique = df[col].nunique()\n",
    "            if isinstance(n_unique, (int, np.integer)):\n",
    "                if n_unique <= 50:\n",
    "                    low_card_cols.append(col)\n",
    "                else:\n",
    "                    high_card_cols.append(col)\n",
    "            else:\n",
    "                print(f\"[跳过] {col} 的 nunique 结果不是标量: {n_unique}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[异常] {col}: {e}\")\n",
    "\n",
    "\n",
    "    # One-hot 编码\n",
    "    X_cat = pd.get_dummies(df[low_card_cols], dummy_na=True)\n",
    "\n",
    "    # Target 编码\n",
    "    if y is not None and high_card_cols:\n",
    "        encoder = ce.TargetEncoder()\n",
    "        X_target = encoder.fit_transform(df[high_card_cols], y)\n",
    "        X_target.columns = [f\"{col}_te\" for col in high_card_cols]\n",
    "    else:\n",
    "        X_target = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 数值标准化\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(df[num_cols]), columns=num_cols, index=df.index)\n",
    "\n",
    "    # 拼接所有\n",
    "    X_final_df = pd.concat([X_num_scaled, X_cat, X_target], axis=1)\n",
    "\n",
    "    return X_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37764e12-604b-4fa8-8751-de2ccf0ab96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_knn_price_features(df, base_df=None, lat_col='latitude', lon_col='longitude',\n",
    "                           target_col='target', ks=[5, 10, 20]):\n",
    "    if base_df is None:\n",
    "        base_df = df  # 默认自己为近邻池\n",
    "\n",
    "    coords_query = df[[lat_col, lon_col]].values\n",
    "    coords_base = base_df[[lat_col, lon_col]].values\n",
    "    tree = KDTree(coords_base, metric='euclidean')\n",
    "\n",
    "    base_targets = base_df[target_col].values\n",
    "    knn_features = {}\n",
    "\n",
    "    for k in ks:\n",
    "        dists, indices = tree.query(coords_query, k=k)\n",
    "        neighbor_targets = base_targets[indices]\n",
    "\n",
    "        knn_features[f'knn_price_mean_{k}'] = neighbor_targets.mean(axis=1)\n",
    "        knn_features[f'knn_price_std_{k}'] = neighbor_targets.std(axis=1)\n",
    "        knn_features[f'knn_price_range_{k}'] = neighbor_targets.max(axis=1) - neighbor_targets.min(axis=1)\n",
    "\n",
    "    for col, val in knn_features.items():\n",
    "        df[col] = val\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d454bb3d-6426-4bc7-8512-9c93d14fcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_radius_knn_features(df, base_df, lat_col='latitude', lon_col='longitude', target_col='target', radius=0.01, max_neighbors=100):\n",
    "    coords = np.radians(base_df[[lat_col, lon_col]])\n",
    "    tree = BallTree(coords, metric='haversine')  # 地理距离计算更准\n",
    "\n",
    "    df_coords = np.radians(df[[lat_col, lon_col]])\n",
    "    indices = tree.query_radius(df_coords, r=radius)\n",
    "\n",
    "    # 每个样本找到若干邻居索引后，聚合\n",
    "    agg_means, agg_stds, agg_counts = [], [], []\n",
    "    base_targets = base_df[target_col].values\n",
    "\n",
    "    for idxs in indices:\n",
    "        if len(idxs) > 1:\n",
    "            if len(idxs) > max_neighbors:\n",
    "                idxs = idxs[:max_neighbors]\n",
    "            neigh_vals = base_targets[idxs]\n",
    "            agg_means.append(np.mean(neigh_vals))\n",
    "            agg_stds.append(np.std(neigh_vals))\n",
    "            agg_counts.append(len(idxs))\n",
    "        else:\n",
    "            agg_means.append(np.nan)\n",
    "            agg_stds.append(np.nan)\n",
    "            agg_counts.append(0)\n",
    "\n",
    "    df['radius_knn_mean'] = agg_means\n",
    "    df['radius_knn_std'] = agg_stds\n",
    "    df['radius_knn_count'] = agg_counts\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496f4d22-7e82-4902-91de-0b0efb318197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_knn_price_features_radius(df, base_df, lat_col='latitude', lon_col='longitude',\n",
    "                                   target_col='sale_price', radius=0.01, max_neighbors=100):\n",
    "    df = df.copy()\n",
    "    \n",
    "    coords_query = df[[lat_col, lon_col]].astype(np.float32).values\n",
    "    coords_base = base_df[[lat_col, lon_col]].astype(np.float32).values\n",
    "    targets_base = base_df[target_col].astype(np.float32).values\n",
    "\n",
    "    tree = KDTree(coords_base, leaf_size=40, metric='euclidean')\n",
    "    neighbor_indices = tree.query_radius(coords_query, r=radius)\n",
    "\n",
    "    means, stds, ranges = [], [], []\n",
    "\n",
    "    for i, inds in enumerate(neighbor_indices):\n",
    "        # 排除自身（仅当 base_df 是 df）\n",
    "        if base_df is df:\n",
    "            inds = inds[inds != i]\n",
    "        \n",
    "        if len(inds) == 0:\n",
    "            means.append(np.nan)\n",
    "            stds.append(np.nan)\n",
    "            ranges.append(np.nan)\n",
    "        else:\n",
    "            if len(inds) > max_neighbors:\n",
    "                inds = inds[:max_neighbors]\n",
    "            vals = targets_base[inds]\n",
    "            means.append(np.mean(vals))\n",
    "            stds.append(np.std(vals))\n",
    "            ranges.append(np.max(vals) - np.min(vals))\n",
    "\n",
    "    df[f'knn_radius_mean'] = means\n",
    "    df[f'knn_radius_std'] = stds\n",
    "    df[f'knn_radius_range'] = ranges\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02daec71-f955-472d-9e1f-7787f8ffa55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 56)\n",
      "['knn_price_mean_5', 'knn_price_std_5', 'knn_price_range_5', 'knn_price_mean_10', 'knn_price_std_10', 'knn_price_range_10', 'knn_price_mean_20', 'knn_price_std_20', 'knn_price_range_20', 'knn_radius_mean', 'knn_radius_std', 'knn_radius_range']\n"
     ]
    }
   ],
   "source": [
    "# 应用预处理\n",
    "# 对训练集（自己做自己）\n",
    "train = add_knn_price_features(train, base_df=train, target_col='sale_price')\n",
    "# 对测试集（用训练集做 base）\n",
    "test = add_knn_price_features(test, base_df=train, target_col='sale_price')\n",
    "\n",
    "train = add_knn_price_features_radius(train, base_df=train, target_col='sale_price')\n",
    "# 对测试集（用训练集做 base）\n",
    "test = add_knn_price_features_radius(test, base_df=train, target_col='sale_price')\n",
    "\n",
    "train_features = train.drop(['sale_price'], axis=1)\n",
    "test_features = test\n",
    "\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "print(features.shape)\n",
    "print([col for col in features.columns if 'knn' in col])\n",
    "\n",
    "X_final = preprocess_and_encode(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7252a9d7-c62e-4fac-810d-08bc7d3f2ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 1134)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0554dc23-908e-4a52-8204-b94f53bcf7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (200000, 1134) y (200000,) X_sub (200000, 1134)\n"
     ]
    }
   ],
   "source": [
    "X = X_final.iloc[:len(train_features)].reset_index(drop=True)\n",
    "X_sub = X_final.iloc[len(train_features):].reset_index(drop=True)\n",
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8f6018d-9f46-4b8d-a6a5-d34b10cf471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['join_status_nan', 'submarket_nan']\n"
     ]
    }
   ],
   "source": [
    "protected_cols = []\n",
    "overfit = [i for i in X.columns if i not in protected_cols and X[i].value_counts().iloc[0] / len(X) * 100 > 99.94]\n",
    "print(overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55135d8b-2df7-4fee-9789-45d504581069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (200000, 1132) y (200000,) X_sub (200000, 1132)\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(overfit, axis=1)\n",
    "X_sub = X_sub.drop(overfit, axis=1)\n",
    "\n",
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e18d7973-5cfd-4ddd-9b50-05bee7819c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_quantile_model(alpha):\n",
    "    return lgb.LGBMRegressor(\n",
    "        objective='quantile',\n",
    "        alpha=alpha,\n",
    "        n_jobs=-1,\n",
    "        num_leaves=4,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=5000,\n",
    "        max_bin=200,\n",
    "        bagging_fraction=0.75,\n",
    "        bagging_freq=5,\n",
    "        bagging_seed=7,\n",
    "        feature_fraction=0.2,\n",
    "        feature_fraction_seed=7,\n",
    "        min_data_in_leaf=20,   # 调大一点防过拟合 tail\n",
    "        verbose=-1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4f75f2-8e3f-4893-b1c2-afdc5c6d4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def train_quantile_model(X, y, quantile):\n",
    "    params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': quantile,\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'min_data_in_leaf': 30,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ee87c5-2990-4586-9a08-e1d752172cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_score(y_true, lower, upper, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Compute Wα for a given prediction interval [lower, upper] and true values y.\n",
    "    \"\"\"\n",
    "    interval_width = upper - lower\n",
    "    below = y_true < lower\n",
    "    above = y_true > upper\n",
    "    inside = (lower <= y_true) & (y_true <= upper)\n",
    "    \n",
    "    penalty = np.zeros_like(y_true, dtype=float)\n",
    "    penalty[below] = (2 / alpha) * (lower[below] - y_true[below])\n",
    "    penalty[above] = (2 / alpha) * (y_true[above] - upper[above])\n",
    "\n",
    "    return np.mean(interval_width + penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9dbf2d-a344-492d-9ff4-db7013e60663",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_lower \u001b[38;5;241m=\u001b[39m get_lgb_quantile_model(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m      8\u001b[0m model_upper \u001b[38;5;241m=\u001b[39m get_lgb_quantile_model(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_lower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model_upper\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     13\u001b[0m pred_lower \u001b[38;5;241m=\u001b[39m model_lower\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_lower = get_lgb_quantile_model(alpha=0.05)\n",
    "model_upper = get_lgb_quantile_model(alpha=0.95)\n",
    "\n",
    "model_lower.fit(X_train, y_train)\n",
    "model_upper.fit(X_train, y_train)\n",
    "\n",
    "pred_lower = model_lower.predict(X_val)\n",
    "pred_upper = model_upper.predict(X_val)\n",
    "\n",
    "score = interval_score(y_val, pred_lower, pred_upper, alpha=0.1)\n",
    "print(f\"W_alpha score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "007ddfb8-03a9-4f6e-9546-af562fbe6379",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_lower \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_quantile_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model_upper \u001b[38;5;241m=\u001b[39m train_quantile_model(X_train, y_train, quantile\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m)\n\u001b[1;32m      4\u001b[0m pred_lower \u001b[38;5;241m=\u001b[39m model_lower\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mtrain_quantile_model\u001b[0;34m(X, y, quantile)\u001b[0m\n\u001b[1;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantile\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: quantile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_lower = train_quantile_model(X_train, y_train, quantile=0.05)\n",
    "model_upper = train_quantile_model(X_train, y_train, quantile=0.95)\n",
    "\n",
    "pred_lower = model_lower.predict(X_val)\n",
    "pred_upper = model_upper.predict(X_val)\n",
    "\n",
    "score = interval_score(y_val, pred_lower, pred_upper, alpha=0.1)\n",
    "print(f\"W_alpha score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28cc685e-a669-4eeb-b4b8-f2426709165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lower = train_quantile_model(X, y, quantile=0.05)\n",
    "model_upper = train_quantile_model(X, y, quantile=0.95)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b638fa04-ad17-4826-972e-1f84562dee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lower = model_lower.predict(X_sub)\n",
    "pred_upper = model_upper.predict(X_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1d0b7dc-3ca2-4261-8de8-c16b7d27310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lower = np.expm1(pred_lower)\n",
    "pred_upper = np.expm1(pred_upper)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ID,  # test 原始数据中的 ID\n",
    "    'pi_lower': pred_lower,  # 下限预测\n",
    "    'pi_upper': pred_upper   # 上限预测\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28c210fa-e6e3-4e78-8788-ff24a7435ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature  importance\n",
      "1098           sale_year        2029\n",
      "37      knn_price_mean_5        1751\n",
      "5               land_val        1131\n",
      "39     knn_price_range_5        1096\n",
      "10                  sqft         971\n",
      "38       knn_price_std_5         953\n",
      "6                imp_val         952\n",
      "1100           house_age         850\n",
      "1               latitude         799\n",
      "7             year_built         719\n",
      "9               sqft_lot         670\n",
      "11                sqft_1         614\n",
      "40     knn_price_mean_10         584\n",
      "43     knn_price_mean_20         516\n",
      "1101            reno_age         498\n",
      "2              longitude         498\n",
      "46       knn_radius_mean         493\n",
      "1103      land_imp_ratio         469\n",
      "1099          sale_month         455\n",
      "42    knn_price_range_10         423\n",
      "45    knn_price_range_20         411\n",
      "41      knn_price_std_10         397\n",
      "44      knn_price_std_20         375\n",
      "47        knn_radius_std         363\n",
      "13                 grade         353\n",
      "22             gara_sqft         343\n",
      "15             condition         338\n",
      "48      knn_radius_range         287\n",
      "12            sqft_fbsmt         241\n",
      "3                   area         218\n",
      "1069      address_pca_22         208\n",
      "1049       address_pca_2         186\n",
      "1048       address_pca_1         182\n",
      "21             garb_sqft         179\n",
      "1050       address_pca_3         177\n",
      "1096      address_pca_49         174\n",
      "1087      address_pca_40         172\n",
      "1051       address_pca_4         172\n",
      "1065      address_pca_18         170\n",
      "1086      address_pca_39         167\n",
      "1089      address_pca_42         166\n",
      "1085      address_pca_38         164\n",
      "1066      address_pca_19         161\n",
      "1097      address_pca_50         159\n",
      "1076      address_pca_29         157\n",
      "17                  beds         156\n",
      "1057      address_pca_10         156\n",
      "1077      address_pca_30         153\n",
      "1090      address_pca_43         152\n",
      "1059      address_pca_12         151\n",
      "                           feature  importance\n",
      "1098                     sale_year        2290\n",
      "37                knn_price_mean_5        2028\n",
      "5                         land_val        1398\n",
      "6                          imp_val        1198\n",
      "10                            sqft         954\n",
      "39               knn_price_range_5         954\n",
      "9                         sqft_lot         868\n",
      "38                 knn_price_std_5         794\n",
      "1                         latitude         740\n",
      "43               knn_price_mean_20         680\n",
      "1100                     house_age         668\n",
      "2                        longitude         628\n",
      "1101                      reno_age         626\n",
      "7                       year_built         570\n",
      "40               knn_price_mean_10         536\n",
      "46                 knn_radius_mean         495\n",
      "1099                    sale_month         487\n",
      "11                          sqft_1         476\n",
      "1103                land_imp_ratio         390\n",
      "22                       gara_sqft         387\n",
      "44                knn_price_std_20         363\n",
      "41                knn_price_std_10         341\n",
      "45              knn_price_range_20         337\n",
      "13                           grade         334\n",
      "42              knn_price_range_10         332\n",
      "48                knn_radius_range         290\n",
      "47                  knn_radius_std         284\n",
      "12                      sqft_fbsmt         282\n",
      "1109  join_status_rebuilt - before         231\n",
      "3                             area         217\n",
      "1096                address_pca_49         167\n",
      "0                        join_year         167\n",
      "1097                address_pca_50         164\n",
      "1095                address_pca_48         160\n",
      "1079                address_pca_32         157\n",
      "1085                address_pca_38         154\n",
      "1073                address_pca_26         152\n",
      "1069                address_pca_22         150\n",
      "1066                address_pca_19         148\n",
      "1087                address_pca_40         146\n",
      "1048                 address_pca_1         146\n",
      "1057                address_pca_10         146\n",
      "1065                address_pca_18         144\n",
      "1060                address_pca_13         144\n",
      "1090                address_pca_43         140\n",
      "1056                 address_pca_9         139\n",
      "1052                 address_pca_5         139\n",
      "1059                address_pca_12         139\n",
      "1068                address_pca_21         138\n",
      "1054                 address_pca_7         137\n"
     ]
    }
   ],
   "source": [
    "def best_features(model):\n",
    "    # 获取特征重要性\n",
    "    importance = model.feature_importances_\n",
    "    features = X_train.columns\n",
    "    \n",
    "    # 打包成 DataFrame\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # 显示前 30 个最重要的特征\n",
    "    print(feat_imp.head(50))\n",
    "\n",
    "\n",
    "best_features(model_lower)\n",
    "best_features(model_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1da2eb-1e09-4391-8b23-ea6beedd8444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.6, 'feature_fraction': 0.6, 'learning_rate': 0.05, 'min_data_in_leaf': 30, 'n_estimators': 2000, 'num_leaves': 16}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_pinball_loss, make_scorer\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [4, 8, 16],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'n_estimators': [1000, 2000],\n",
    "    'feature_fraction': [0.6, 0.8],\n",
    "    'bagging_fraction': [0.6, 0.8],\n",
    "    'min_data_in_leaf': [20, 30],\n",
    "}\n",
    "\n",
    "def pinball_scorer(y_true, y_pred):\n",
    "    return -mean_pinball_loss(y_true, y_pred, alpha=0.05)\n",
    "\n",
    "scorer = make_scorer(pinball_scorer, greater_is_better=True)\n",
    "\n",
    "\n",
    "model = lgb.LGBMRegressor(objective='quantile', alpha=0.05)\n",
    "grid = GridSearchCV(model, param_grid, cv=3, scoring=scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198ba3d-da01-4717-893d-87880c41a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'alpha': 0.05,  # 下限模型\n",
    "    'num_leaves': 16,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 2000,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "model_lower = lgb.LGBMRegressor(**params)\n",
    "model_lower.fit(X_train, y_train)\n",
    "\n",
    "# 上限只改 alpha\n",
    "params['alpha'] = 0.95\n",
    "model_upper = lgb.LGBMRegressor(**params)\n",
    "model_upper.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee354556-92ae-46fd-94b2-c76989aa06e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_param_set(X, y, param_overrides):\n",
    "    base_params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': 0.05,\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'min_data_in_leaf': 30,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    base_params.update(param_overrides)\n",
    "    model = lgb.LGBMRegressor(**base_params)\n",
    "    scores = cv_rmse(model, X)\n",
    "    return np.mean(scores), param_overrides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c19c11a4-7cce-475b-ae79-dcdce4b812e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leaves \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         score, params \u001b[38;5;241m=\u001b[39m \u001b[43mtry_param_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_leaves\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(score, params)\n",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m, in \u001b[0;36mtry_param_set\u001b[0;34m(X, y, param_overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m base_params\u001b[38;5;241m.\u001b[39mupdate(param_overrides)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_params)\n\u001b[0;32m---> 12\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcv_rmse\u001b[49m(model, X)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores), param_overrides\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "for leaves in [4, 8, 16]:\n",
    "    for lr in [0.01, 0.05]:\n",
    "        score, params = try_param_set(X, y, {'num_leaves': leaves, 'learning_rate': lr})\n",
    "        print(score, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c442ba-b174-4669-a43b-5b7adf0c4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 15,\n",
    "    'min_samples_split': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "gbr_lower = GradientBoostingRegressor(loss='quantile', alpha=0.05, **other_params)\n",
    "gbr_upper = GradientBoostingRegressor(loss='quantile', alpha=0.95, **other_params)\n",
    "\n",
    "gbr_lower.fit(X_train, y_train)\n",
    "gbr_upper.fit(X_train, y_train)\n",
    "\n",
    "pred_lower = gbr_lower.predict(X_val)\n",
    "pred_upper = gbr_upper.predict(X_val)\n",
    "\n",
    "# 评估 W_alpha\n",
    "score = interval_score(y_val, pred_lower, pred_upper, alpha=0.1)\n",
    "print(f\"W_alpha score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e9ce6-b21a-4aad-9241-d21b6a84fa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665639c3-2b4c-4a83-b866-846354915524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(model):\n",
    "    # 获取特征重要性\n",
    "    importance = model.feature_importances_\n",
    "    features = X_train.columns\n",
    "    \n",
    "    # 打包成 DataFrame\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # 显示前 30 个最重要的特征\n",
    "    print(feat_imp.head(30))\n",
    "\n",
    "\n",
    "best_features(model_lower)\n",
    "best_features(model_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31328014-5ed6-4526-bed0-7c72d4da23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in X.columns if 'knn_price' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68423cc6-ef17-4465-9dfe-2a9a237479cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_knn_price_features(df, lat_col='latitude', lon_col='longitude', target_col='target', ks=[5, 10, 20]):\n",
    "    coords = df[[lat_col, lon_col]].values\n",
    "    target = df[target_col].values\n",
    "    tree = KDTree(coords, metric='euclidean')\n",
    "\n",
    "    # 用于保存所有新特征\n",
    "    knn_features = {}\n",
    "\n",
    "    for k in ks:\n",
    "        # 找最近邻（包括自己）\n",
    "        dists, indices = tree.query(coords, k=k+1)  # k+1 是因为自己也算在内\n",
    "\n",
    "        # 排除自身\n",
    "        neighbor_targets = np.array([target[idxs[1:]] for idxs in indices])\n",
    "\n",
    "        # 聚合统计\n",
    "        knn_features[f'knn_price_mean_{k}'] = neighbor_targets.mean(axis=1)\n",
    "        knn_features[f'knn_price_std_{k}'] = neighbor_targets.std(axis=1)\n",
    "        knn_features[f'knn_price_range_{k}'] = neighbor_targets.max(axis=1) - neighbor_targets.min(axis=1)\n",
    "\n",
    "    # 加入原始 df\n",
    "    for col_name, values in knn_features.items():\n",
    "        df[col_name] = values\n",
    "\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61408d67-50a8-4b1a-866b-ecde8ecbbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df 中已经有 latitude、longitude、target（真实价格）列\n",
    "df = add_knn_price_features(train, target_col='sale_price', ks=[5, 10, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8101d-ed9f-4ab5-ae09-6267a65367f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_knn_feature(df, feature_col='knn_price_mean_5'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(df['longitude'], df['latitude'], \n",
    "                     c=df[feature_col], cmap='viridis', s=5)\n",
    "    plt.colorbar(sc, label=feature_col)\n",
    "    plt.title(f'Spatial distribution of {feature_col}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22775e20-a8d3-43ec-a251-a34c5f018634",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knn_feature(df, 'knn_price_mean_20')\n",
    "plot_knn_feature(df, 'knn_price_mean_10')\n",
    "plot_knn_feature(df, 'knn_price_mean_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de80cfd-f6d2-4a08-bcbb-5afedd9582f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train.copy()\n",
    "addresses = (df['city'].fillna('') + ' ' + df['subdivision'].fillna('')).str.lower()\n",
    "\n",
    "# 分词（空格切）\n",
    "# 用 CountVectorizer 可以保留频率稀疏性\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,         # 可调大小\n",
    "    stop_words=None,      # 去常见词\n",
    "    token_pattern=r'\\b\\w+\\b',  # 标准单词\n",
    "    ngram_range=(1, 2)         # 一元和二元组都试试\n",
    ")\n",
    "address_vecs = vectorizer.fit_transform(addresses)\n",
    "\n",
    "# 得到 token -> index 映射\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "# 每个 token 的总出现频率（在所有样本中出现的总次数）\n",
    "token_freq = np.asarray(address_vecs.sum(axis=0)).ravel()\n",
    "\n",
    "# 排序\n",
    "sorted_idx = np.argsort(-token_freq)\n",
    "top_tokens = [(tokens[i], token_freq[i]) for i in sorted_idx[:200]]\n",
    "\n",
    "# 展示前 50 个 token 和它们的频率\n",
    "for t, f in top_tokens:\n",
    "    print(f\"{t}: {f}\")\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "address_pca = svd.fit_transform(address_vecs)\n",
    "\n",
    "# 累计解释方差\n",
    "explained = np.cumsum(svd.explained_variance_ratio_)\n",
    "plt.plot(range(1, len(explained) + 1), explained)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Truncated SVD on Address')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3fdd0-f3b7-4802-8583-f636b1f07089",
   "metadata": {},
   "outputs": [],
   "source": [
    "待处理特征：\n",
    "改造时间距离现在多少年\n",
    "地址经纬度做近邻，最好找出价格最高的中心点\n",
    "尝试销售年份和submarke捆绑，销售月份和地区捆绑\n",
    "PCA提取地址主成分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233b735-83d5-4e99-9ca9-85fd45af8a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
